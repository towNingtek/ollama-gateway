#!/usr/bin/env bash
# Run all LLM smoke tests and save outputs.
set -euo pipefail

PROMPT="${*:-çµ¦æˆ‘ä¸‰å€‹å®¢æœå•å€™èª}"
OUTDIR="scripts/llm/out"
mkdir -p "$OUTDIR"

ts="$(date +%Y%m%d-%H%M%S)"

have() { command -v "$1" >/dev/null 2>&1; }

ensure_script() {
  local p="$1"
  if [ ! -x "$p" ]; then
    echo "[SKIP] $p ä¸å­˜åœ¨æˆ–ä¸å¯åŸ·è¡Œï¼ˆè·³éï¼‰"
    return 1
  fi
  return 0
}

run() {
  local title="$1"; shift
  local file="$OUTDIR/${ts}_${title}.txt"

  echo "=== $title ==="
  local start end dur code

  # ç¢ºä¿ä¸å› å–®ä¸€é …ç›®å‡ºéŒ¯è€Œä¸­æ–·æ•´æ‰¹
  set +e
  start=$(date +%s)

  # æŠŠ stdout+stderr åŒæ­¥å°å‡º & å­˜æª”
  "$@" 2>&1 | tee "$file"
  code=${PIPESTATUS[0]}

  end=$(date +%s)
  set -e
  dur=$(( end - start ))

  if [ $code -ne 0 ]; then
    echo "[ERR] $title exited $codeï¼ˆè©³è¦‹ $fileï¼‰" | tee -a "$file"
  fi
  echo "[done $title in ${dur}s]"
  echo
}

# å…è¨±ç”¨ç’°å¢ƒè®Šæ•¸è¦†è“‹ï¼ˆä¾‹å¦‚ OPTIONS_JSONã€SYSã€MODELã€GATEWAYï¼‰
export PROMPT

# æª¢æŸ¥è…³æœ¬å­˜åœ¨æ€§ï¼ˆä¸å­˜åœ¨å°±è·³éï¼‰
declare -A CMDS=(
  ["llama_nonstream"]="scripts/llm/llama_chat.sh"
  ["llama_stream"]="scripts/llm/llama_chat_stream.sh"
  ["openai_nonstream"]="scripts/llm/openai_chat.sh"
  ["openai_stream"]="scripts/llm/openai_chat_stream.sh"
)

for key in "${!CMDS[@]}"; do
  ensure_script "${CMDS[$key]}" || unset "CMDS[$key]"
done

# é€ä¸€è·‘ï¼ˆæœ‰å°±è·‘ï¼‰
[ -n "${CMDS[llama_nonstream]+x}" ]  && run "llama_nonstream"  "${CMDS[llama_nonstream]}"  "$PROMPT"
[ -n "${CMDS[llama_stream]+x}" ]     && run "llama_stream"     "${CMDS[llama_stream]}"     "$PROMPT"
[ -n "${CMDS[openai_nonstream]+x}" ] && run "openai_nonstream" "${CMDS[openai_nonstream]}" "$PROMPT"
[ -n "${CMDS[openai_stream]+x}" ]    && run "openai_stream"    "${CMDS[openai_stream]}"    "$PROMPT"

echo "ğŸ“„ Saved to ${OUTDIR}/${ts}_*.txt"

